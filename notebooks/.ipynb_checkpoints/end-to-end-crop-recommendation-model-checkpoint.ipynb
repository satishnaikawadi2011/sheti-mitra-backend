{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending A Crop Using Machine Learning\n",
    "\n",
    "This notebook will introduce some foundation machine learning and data science concepts by exploring the problem of crop recommendation **classification**.\n",
    "\n",
    "\n",
    "## What is classification?\n",
    "\n",
    "Classification involves deciding whether a sample is part of one class or another (**single-class classification**). If there are multiple class options, it's referred to as **multi-class classification**.\n",
    "\n",
    "## What we'll end up with\n",
    "\n",
    "Since we already have a dataset, we'll approach the problem by keeping the following topics in our mind.\n",
    "\n",
    "* **Exploratory data analysis (EDA)** - the process of going through a dataset and finding out more about it.\n",
    "* **Model training** - create model(s) to learn to predict a target variable based on other variables.\n",
    "* **Model evaluation** - evaluating a models predictions using problem-specific evaluation metrics. \n",
    "* **Model comparison** - comparing several different models to find the best one.\n",
    "* **Model fine-tuning** - once we've found a good model, how can we improve it?\n",
    "* **Feature importance** - since we're recommending a crop, are there some things which are more important for prediction?\n",
    "* **Cross-validation** - if we do build a good model, can we be sure it will work on unseen data?\n",
    "* **Reporting what we've found** - if we had to present our work, what would we show someone?\n",
    "\n",
    "To work through these topics, we'll use pandas, Matplotlib and NumPy for data anaylsis, as well as, Scikit-Learn for machine learning and modelling tasks.\n",
    "\n",
    "We'll work through each step and by the end of the notebook, we'll have a handful of models, all which can predict whether or not a person has heart disease based on a number of different parameters at a considerable accuracy. \n",
    "\n",
    "We will also describe which parameters are more indicative than others, for example, rainfall may be more important than temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "In our case, the problem we will be exploring is **multiclass classification** (A classification task with more than two classes). \n",
    "\n",
    "This is because we're going to be using a number of differnet **features** (pieces of information) about a farm to recommend a crop which will be best suited for that farm\n",
    "\n",
    "In a statement,\n",
    "\n",
    "> Given clinical parameters about a farm, can we recommend a best suited crop for that farm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "What we want to do here is dive into the data our problem definition is based on. This may involve, sourcing, defining different parameters, talking to experts about it and finding out what you should expect.\n",
    "\n",
    "We've downloaded this data in a formatted way from [Kaggle](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset).\n",
    "\n",
    "This dataset contains only 7 attributes. **Attributes** (also called **features**) are the variables what we'll use to predict our **target variable**.\n",
    "\n",
    "Attributes and features are also referred to as **independent variables** and a target variable can be referred to as a **dependent variable**.\n",
    "\n",
    "> We use the independent variables to predict our dependent variable.\n",
    "\n",
    "Or in our case, the independent variables are a different attributes related to a farm and the dependent variable what type of crop is suitable for a given farm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "The evaluation metric is something we want to define at the start of a project.\n",
    "\n",
    "Since machine learning is very experimental, we can say something like, \n",
    "\n",
    "> If we can reach 90% accuracy at predicting suitable crop for a given farm during the proof of concept, we'll pursure this project.\n",
    "\n",
    "The reason this is helpful is it provides a rough goal for a machine learning engineer or data scientist to work towards.\n",
    "\n",
    "However, due to the nature of experimentation, the evaluation metric may change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features\n",
    "\n",
    "Features are different parts of the data. During this step, we will start finding out what we can about the data.\n",
    "\n",
    "One of the most common ways to do this, is to create a **data dictionary**.\n",
    "\n",
    "### Crop Recommendation Data Dictionary\n",
    "\n",
    "A data dictionary describes the data we are dealing with. Not all datasets come with them so this is where we have to do our research or ask a **subject matter expert** (someone who knows about the data) for more.\n",
    "\n",
    "The following are the features we'll use to predict our target variable (suitable crop for a farm).\n",
    "\n",
    "1. N - ratio of Nitrogen content in soil\n",
    "2. P - ratio of Phosphorous content in soil\n",
    "3. K - ratio of Potassium content in soil\n",
    "4. temperature - temperature in degree Celsius\n",
    "5. humidity - relative humidity in %\n",
    "6. ph - ph value of the soil\n",
    "7. rainfall - rainfall in mm\n",
    "8. label - type of crop recommended for a given farm \n",
    "    ('rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
    "      'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
    "      'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
    "      'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee') (= the predicted attribute)\n",
    "\n",
    "**Note:** No personal identifiable information (PPI) can be found in the dataset.\n",
    "\n",
    "It's a good idea to save these to a Python dictionary or in an external file, so we can look at them later without coming back here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the tools\n",
    "\n",
    "At the start of any project, it's custom to see the required libraries imported in a big chunk.\n",
    "\n",
    "The libraries we use will differ from project to project. But there are a few which we can take advantage of during almost every structured data project. \n",
    "\n",
    "* [pandas](https://pandas.pydata.org/) for data analysis.\n",
    "* [NumPy](https://numpy.org/) for numerical operations.\n",
    "* [Matplotlib](https://matplotlib.org/)/[seaborn](https://seaborn.pydata.org/) for plotting or data visualization.\n",
    "* [Scikit-Learn](https://scikit-learn.org/stable/) for machine learning modelling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular EDA and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# We want our plots to appear in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "## Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Model evaluators\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "There are many different kinds of ways to store data. The typical way of storing **tabular data**, data similar to what you'd see in an Excel file is in `.csv` format. `.csv` stands for comma seperated values.\n",
    "\n",
    "Pandas has a built-in function to read `.csv` files called `read_csv()` which takes the file pathname of your `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/Crop_recommendation.csv\");\n",
    "df.shape # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
